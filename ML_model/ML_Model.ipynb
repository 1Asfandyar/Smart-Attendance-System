{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_PROJECT_UPDATED.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/1Asfandyar/Smart-Attendance-System/blob/flask_api/ML_model/ML_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"/content/drive/MyDrive/ML_Project/StudentName.pkl\"\n",
        "\n",
        "\n",
        "open_file = open(file_name, \"rb\")\n",
        "personNames = pickle.load(open_file)\n",
        "open_file.close()\n",
        "\n",
        "\n",
        "file_name = \"/content/drive/MyDrive/ML_Project/StudentEncoding.pkl\"\n",
        "\n",
        "open_file = open(file_name, \"rb\")\n",
        "encodeListKnown = pickle.load(open_file)\n",
        "open_file.close()\n",
        "\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "folder = '/content/drive/MyDrive/ML_Project/ClassroomPicture/'\n",
        "    \n",
        "for filename in os.listdir(folder):\n",
        "    print(filename)\n",
        "    img = cv2.imread(os.path.join(folder,filename))\n",
        "    if img is not None:\n",
        "\n",
        "\n",
        "      Path = os.path.join(folder,filename)\n",
        "\n",
        "      image = face_recognition.load_image_file(Path)\n",
        "\n",
        "\n",
        "      detector = MTCNN()\n",
        "\n",
        "      faces = detector.detect_faces(image)\n",
        "\n",
        "      face_location1 = []\n",
        "      for face in faces:\n",
        "        x,y,w,h = face['box']\n",
        "\n",
        "        x1 = y\n",
        "        w1 = y+h\n",
        "        h1 = x\n",
        "        y1 = x+w\n",
        "\n",
        "        a = (x1, y1, w1, h1)\n",
        "        face_location1.append(a)\n",
        "\n",
        "\n",
        "      encodesCurrentFrame = face_recognition.face_encodings(image, face_location1)\n",
        "\n",
        "      \n",
        "      ImageContours = cv2.imread(Path)\n",
        "      ImageContours = cv2.cvtColor(ImageContours,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      ReplicateImage = ImageContours.copy()\n",
        "\n",
        "      for cntr in face_location1:\n",
        "          x,y,w,h = cntr\n",
        "          cv2.rectangle(ReplicateImage, (h, x), (y, w), (0, 0, 255), 2)\n",
        "\n",
        "      cv2.imwrite('/content/drive/MyDrive/ML_Project/Output_Image/'+ filename ,ReplicateImage)\n",
        "\n",
        "      Name_Dist = {}\n",
        "      Not_sure = []\n",
        "      # Not_sure1 = []\n",
        "      for encodeFace, faceLoc in zip(encodesCurrentFrame, face_location1):\n",
        "              matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
        "              \n",
        "              faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
        "              # print(faceDis)\n",
        "              matchIndex = np.argmin(faceDis)\n",
        "              match_threshold = np.min(faceDis)\n",
        "              # print(matchIndex)\n",
        "              if faceDis[matchIndex] < 0.50:\n",
        "                  name = personNames[matchIndex].upper()\n",
        "                  # print(name)\n",
        "                  Name_Dist[name] = [match_threshold,faceLoc]\n",
        "              else:\n",
        "                  name = personNames[matchIndex].upper()\n",
        "                  \n",
        "                  if name not in Not_sure:\n",
        "                    if name not in Name_Dist:\n",
        "\n",
        "                      enc = (name, match_threshold,faceLoc)\n",
        "                      Not_sure.append(enc)\n",
        "                  \n",
        "\n",
        "\n",
        "                  # print('Unknown')\n",
        "                  # Name_Dist['Unknown'] = faceLoc\n",
        "      NOT_SURE_DIST = {}\n",
        "\n",
        "      for Face in Not_sure:\n",
        "        \n",
        "        Name = Face[0]\n",
        "        if Name not in Name_Dist:\n",
        "          prop = []\n",
        "          prop.append(Face[1])\n",
        "          for temp_Face in Not_sure:\n",
        "            if Name == temp_Face[0]:\n",
        "              prop.append(Face[1])\n",
        "          min = np.min(prop)\n",
        "\n",
        "          for temp in Not_sure:\n",
        "            if temp[0] == Name and temp[1] == min:\n",
        "              NOT_SURE_DIST[Name] = [temp[1] ,temp[2]]\n",
        "              # print(Name)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "      image = Image.open('/content/drive/MyDrive/ML_Project/Output_Image/'+ filename)\n",
        "\n",
        "      draw = ImageDraw.Draw(image)\n",
        "\n",
        "      font = ImageFont.truetype('/content/drive/MyDrive/ML_Project/Roboto[wdth,wght].ttf', size=45)\n",
        "\n",
        "      for key in Name_Dist:\n",
        "        A = Name_Dist[key][1]\n",
        "        (x, y) = (A[1], A[0])\n",
        "        message = str(key)\n",
        "        color = 'rgb(0, 0, 0)'\n",
        "        # print(x,y)\n",
        "        draw.text((x, y), message, fill=color, font=font)\n",
        "\n",
        "      for key in NOT_SURE_DIST:\n",
        "        A = NOT_SURE_DIST[key][1]\n",
        "        (x, y) = (A[1], A[0])\n",
        "        message = str(key)\n",
        "        color = 'rgb(255, 0, 0)'\n",
        "        # print(x,y)\n",
        "        draw.text((x, y), message, fill=color, font=font)\n",
        "      \n",
        "      image.save('/content/drive/MyDrive/ML_Project/Output_Image/'+ filename)"
      ],
      "metadata": {
        "id": "9sRQm6aQQ1bG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Installing Face_Recognition Library**"
      ],
      "metadata": {
        "id": "96gX7ErJtlhR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1yP2R-gl7ut"
      },
      "outputs": [],
      "source": [
        "!pip install face_recognition\n",
        "!pip install -v --install-option=\"--no\" --install-option=\"DLIB_USE_CUDA\" dlib\n",
        "!pip install mtcnn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Libraries**"
      ],
      "metadata": {
        "id": "xznyXKY5tsum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import face_recognition\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from datetime import datetime\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import pickle\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "from matplotlib.patches import Circle\n",
        "from mtcnn.mtcnn import MTCNN\n"
      ],
      "metadata": {
        "id": "CyMVnOLIl-Vs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "H4kLfYDTmAbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setup Google Drive**\n",
        "\n",
        "As we have to read and write Data from the google drive and all the required data is shared with all the group members. \n",
        "\n",
        "For all those have shared files have to create a shortcut to root of the drive to work this.\n",
        "\n",
        "**Procedue**\n",
        "\n",
        "\n",
        "1.   Select the ML_Project folder in side 'Shared with me' in the Drive, which is shared with you.\n",
        "2.   Right click on this folder.\n",
        "\n",
        "3. Click Add Short Cut to Drive.\n",
        "\n",
        "4. Add short cut to the root of the My Drive.\n",
        "\n"
      ],
      "metadata": {
        "id": "to2ab46RYNoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Face Encoding Function**"
      ],
      "metadata": {
        "id": "fdzbNajBt2Pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def faceEncodings(images):\n",
        "    encodeList = []\n",
        "    for img in images:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        encode = face_recognition.face_encodings(img)[0]\n",
        "        encodeList.append(encode)\n",
        "    return encodeList"
      ],
      "metadata": {
        "id": "csLV0v63t7em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dont Run This, If you dont add new student picture in Class data**\n",
        "\n",
        "From Drive, Loading All images and Store the name of Student in a List, So that we can predict"
      ],
      "metadata": {
        "id": "XtmRnTe6uCEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/ML_Project/Student_Faces'\n",
        "images = []\n",
        "personNames = []\n",
        "myList = os.listdir(path)\n",
        "# print(myList)\n",
        "for cu_img in myList:\n",
        "    current_Img = cv2.imread(f'{path}/{cu_img}')\n",
        "    images.append(current_Img)\n",
        "    personNames.append(os.path.splitext(cu_img)[0])\n",
        "print(personNames)\n",
        "\n",
        "\n",
        "\n",
        "file_name = \"/content/drive/MyDrive/ML_Project/StudentName.pkl\"\n",
        "\n",
        "open_file = open(file_name, \"wb\")\n",
        "pickle.dump(personNames, open_file)\n",
        "open_file.close()"
      ],
      "metadata": {
        "id": "Y1cIPFV5t9TR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save  face Encoding**"
      ],
      "metadata": {
        "id": "aRqOVDf9uOj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encodeListKnown = faceEncodings(images)\n",
        "\n",
        "import pickle\n",
        "\n",
        "file_name = \"/content/drive/MyDrive/ML_Project/StudentEncoding.pkl\"\n",
        "\n",
        "open_file = open(file_name, \"wb\")\n",
        "pickle.dump(encodeListKnown, open_file)\n",
        "open_file.close()"
      ],
      "metadata": {
        "id": "i3shsN6GuP3w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Student and Face encoding Stored in Drive**"
      ],
      "metadata": {
        "id": "FPRCbqmluWfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = \"/content/drive/MyDrive/ML_Project/StudentName.pkl\"\n",
        "\n",
        "\n",
        "open_file = open(file_name, \"rb\")\n",
        "personNames = pickle.load(open_file)\n",
        "open_file.close()\n",
        "\n",
        "\n",
        "file_name = \"/content/drive/MyDrive/ML_Project/StudentEncoding.pkl\"\n",
        "\n",
        "open_file = open(file_name, \"rb\")\n",
        "encodeListKnown = pickle.load(open_file)\n",
        "open_file.close()"
      ],
      "metadata": {
        "id": "PmAuDEiXuaZx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**INFERENCE**\n",
        "1. loading Image\n",
        "2. Finding Faces in Group image\n",
        "3. Find New Faces Encodings"
      ],
      "metadata": {
        "id": "n3VwnA_FugTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "Path = '/content/drive/MyDrive/ML_Project/ClassroomPicture/IMG_20220315_095343_1.jpg'\n",
        "\n",
        "\n",
        "image = face_recognition.load_image_file(Path)\n",
        "\n",
        "\n",
        "detector = MTCNN()\n",
        "\n",
        "faces = detector.detect_faces(image)\n",
        "\n",
        "face_location1 = []\n",
        "for face in faces:\n",
        "  x,y,w,h = face['box']\n",
        "\n",
        "  x1 = y\n",
        "  w1 = y+h\n",
        "  h1 = x\n",
        "  y1 = x+w\n",
        "\n",
        "  a = (x1, y1, w1, h1)\n",
        "  face_location1.append(a)\n",
        "\n",
        "\n",
        "encodesCurrentFrame = face_recognition.face_encodings(image, face_location1)"
      ],
      "metadata": {
        "id": "rFDeIhLwmGj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking How many Faces detected**"
      ],
      "metadata": {
        "id": "YxOm5HcUv1P5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(face_location1))\n"
      ],
      "metadata": {
        "id": "2lxw0V6Kv1F7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Draw Bounding Box across New Faces Detected**"
      ],
      "metadata": {
        "id": "o8Bbi-wVwBGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "ImageContours = cv2.imread(Path)\n",
        "ImageContours = cv2.cvtColor(ImageContours,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "ReplicateImage = ImageContours.copy()\n",
        "\n",
        "for cntr in face_location1:\n",
        "    x,y,w,h = cntr\n",
        "    cv2.rectangle(ReplicateImage, (h, x), (y, w), (0, 0, 255), 2)\n",
        "\n",
        "cv2.imwrite('/content/drive/MyDrive/ML_Project/Output_Image/Marked_Face_Image.jpg',ReplicateImage)"
      ],
      "metadata": {
        "id": "aMySC4Vxv1bL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Printing Size of Faces**"
      ],
      "metadata": {
        "id": "AgQNoM_nwRba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for cntr in face_location1:\n",
        "    x,y,w,h = cntr\n",
        "    print('Face Size =  ', w-x, ' , ', y-h) "
      ],
      "metadata": {
        "id": "88HeVlVawR39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.path.basename(Path)"
      ],
      "metadata": {
        "id": "EyGesbvhSTL9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparing Both Encodings, Stored in Distionary**\n"
      ],
      "metadata": {
        "id": "-Sm-QxH3wUs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Name_Dist = {}\n",
        "for encodeFace, faceLoc in zip(encodesCurrentFrame, face_location1):\n",
        "        matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
        "        # print(matches)\n",
        "        faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
        "        print(faceDis)\n",
        "        matchIndex = np.argmin(faceDis)\n",
        "        # print(matchIndex)\n",
        "        if faceDis[matchIndex] < 0.50:\n",
        "            name = personNames[matchIndex].upper()\n",
        "            print(name)\n",
        "            Name_Dist[name] = faceLoc\n",
        "        else:\n",
        "            print('Unknown')\n",
        "            Name_Dist['Unknown'] = faceLoc\n",
        "\n"
      ],
      "metadata": {
        "id": "0TycPEn5wU8z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Writing Name on the Faces**"
      ],
      "metadata": {
        "id": "TjPDYtIXwlxf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open('/content/drive/MyDrive/ML_Project/Output_Image/Marked_Face_Image.jpg')\n",
        "\n",
        "draw = ImageDraw.Draw(image)\n",
        "\n",
        "font = ImageFont.truetype('/content/drive/MyDrive/ML_Project/Roboto[wdth,wght].ttf', size=45)\n",
        "\n",
        "for key in Name_Dist:\n",
        "  A = Name_Dist[key][1]\n",
        "  (x, y) = (A[1], A[0])\n",
        "  message = str(key)\n",
        "  color = 'rgb(0, 0, 0)'\n",
        "  # print(x,y)\n",
        "  draw.text((x, y), message, fill=color, font=font)\n",
        "\n",
        "for key in NOT_SURE_DIST:\n",
        "  A = NOT_SURE_DIST[key][1]\n",
        "  (x, y) = (A[1], A[0])\n",
        "  message = str(key)\n",
        "  color = 'rgb(255, 0, 0)'\n",
        "  # print(x,y)\n",
        "  draw.text((x, y), message, fill=color, font=font)\n",
        " \n",
        "image.save('/content/drive/MyDrive/ML_Project/Output_Image/Label_Face_Image_NOT_SURE.jpg')"
      ],
      "metadata": {
        "id": "4TRYC3z6wpK-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in Not_sure:\n",
        "  if i not in Name_Dist:\n",
        "    Name_Dist[i] = Not_sure[i]\n"
      ],
      "metadata": {
        "id": "oI-O_YQpDcZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Name_Dist = {}\n",
        "Not_sure = []\n",
        "Not_sure1 = []\n",
        "for encodeFace, faceLoc in zip(encodesCurrentFrame, face_location1):\n",
        "        matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
        "        \n",
        "        faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
        "        print(faceDis)\n",
        "        matchIndex = np.argmin(faceDis)\n",
        "        match_threshold = np.min(faceDis)\n",
        "        # print(matchIndex)\n",
        "        if faceDis[matchIndex] < 0.50:\n",
        "            name = personNames[matchIndex].upper()\n",
        "            print(name)\n",
        "            Name_Dist[name] = [match_threshold,faceLoc]\n",
        "        else:\n",
        "            name = personNames[matchIndex].upper()\n",
        "            print(name)\n",
        "            # Not_sure[name] = [match_threshold,faceLoc]\n",
        "            if name not in Not_sure:\n",
        "              if name not in Name_Dist:\n",
        "\n",
        "            enc = (name, match_threshold,faceLoc)\n",
        "            Not_sure.append(enc)\n",
        "            \n",
        "\n",
        "\n",
        "            print('Unknown')\n",
        "            # Name_Dist['Unknown'] = faceLoc\n"
      ],
      "metadata": {
        "id": "OYJup-05-6Eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extra Code**"
      ],
      "metadata": {
        "id": "uLr4V_Lxx-bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Name_Dist"
      ],
      "metadata": {
        "id": "MhLeQLAOKCzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Not_sure"
      ],
      "metadata": {
        "id": "c3kKffa9H7k7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "NOT_SURE_DIST = {}\n",
        "\n",
        "for Face in Not_sure:\n",
        "  \n",
        "  Name = Face[0]\n",
        "  if Name not in Name_Dist:\n",
        "    prop = []\n",
        "    prop.append(Face[1])\n",
        "    for temp_Face in Not_sure:\n",
        "      if Name == temp_Face[0]:\n",
        "        prop.append(Face[1])\n",
        "    min = np.min(prop)\n",
        "\n",
        "    for temp in Not_sure:\n",
        "      if temp[0] == Name and temp[1] == min:\n",
        "        NOT_SURE_DIST[Name] = [temp[1] ,temp[2]]\n",
        "        # print(Name)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-TFujr3dNnyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image=cv2.imread(Path)\n",
        "x, y, w, h = face_location1[5]\n",
        "plt.imshow(image[  x:w,h:y])"
      ],
      "metadata": {
        "id": "R3hDrcjdn36x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**A High Level Function to access this Ml Model**\n",
        "\n",
        "This function can be thinl of the abstraction of this whole model which can be called from other files"
      ],
      "metadata": {
        "id": "aq5dtFH0Z6Eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_present_students():\n",
        "  pass"
      ],
      "metadata": {
        "id": "Zmwx4Rn2a6oJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path = '/content/drive/MyDrive/ML_Project/ClassroomPicture/pp.jpg'\n",
        "\n",
        "# image = face_recognition.load_image_file(Path)\n",
        "\n",
        "# face_locations = face_recognition.face_locations(image)\n",
        "\n",
        "# encodesCurrentFrame = face_recognition.face_encodings(image, face_locations)"
      ],
      "metadata": {
        "id": "cP9fqT9Luge2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(face_locations)"
      ],
      "metadata": {
        "id": "AfFrgJ64naC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #!/usr/bin/python\n",
        "# # -*- coding: utf-8 -*-\n",
        "# from matplotlib import pyplot\n",
        "# from matplotlib.patches import Rectangle\n",
        "# from matplotlib.patches import Circle\n",
        "# from mtcnn.mtcnn import MTCNN\n",
        "\n",
        "\n",
        "# def draw_image_with_boxes(filename, result_list):\n",
        "\n",
        "#     data = pyplot.imread(filename)\n",
        "#     pyplot.imshow(data)\n",
        "\n",
        "#     ax = pyplot.gca()\n",
        "#     print('h1')\n",
        "#     for result in result_list:\n",
        "\n",
        "#        # a = 1\n",
        "\n",
        "        \n",
        "\n",
        "#         (x, y, width, height) = result['box']\n",
        "#         print('Dimension:' ,width, height)\n",
        "#         rect = Rectangle((x, y), width, height, fill=False, color='red')\n",
        "\n",
        "#         ax.add_patch(rect)\n",
        "\n",
        "#         for (key, value) in result['keypoints'].items():\n",
        "\n",
        "#             dot = Circle(value, radius=2, color='red')\n",
        "#             ax.add_patch(dot)\n",
        "\n",
        "#     pyplot.show()\n",
        "\n",
        "\n",
        "# # filename = 'pp.jpg'\n",
        "# # filename = 'IMG_20220315_095307.jpg'\n",
        "\n",
        "# # filename = '/content/IMG_20220315_095343_1.jpg'\n",
        "# filename = '/content/drive/MyDrive/ML_Project/ClassroomPicture/IMG_20220315_095343_1.jpg'\n",
        "\n",
        "# pixels = pyplot.imread(filename)\n",
        "\n",
        "# detector = MTCNN()\n",
        "\n",
        "# faces = detector.detect_faces(pixels)\n",
        "# print ('Face Detected: ', len(faces))\n",
        "\n",
        "# draw_image_with_boxes(filename, faces)\n"
      ],
      "metadata": {
        "id": "epUzjGphnjP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(faces[0]['box'])"
      ],
      "metadata": {
        "id": "dY4MhFU3pJQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x,y,w,h = faces[0]['box']"
      ],
      "metadata": {
        "id": "i9EHbS3Hp11G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plt.imshow(image[y:y+h, x:x+w])"
      ],
      "metadata": {
        "id": "0vyMdLP0pJNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x,y,w,h = faces[0]['box']\n",
        "\n",
        "# x1 = y\n",
        "# w1 = y+h\n",
        "# h1 = x\n",
        "# y1 = x+w\n",
        "\n",
        "\n",
        "# plt.imshow(image[  x1:w1,h1:y1])"
      ],
      "metadata": {
        "id": "xtEtdWjYqet5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# x, y, w, h = face_locations[0]\n",
        "# plt.imshow(image[  x:w,h:y])"
      ],
      "metadata": {
        "id": "vFY40ZujqAXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(face_locations)"
      ],
      "metadata": {
        "id": "gX-XhqdqqixF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# face_location1 = []\n",
        "# for face in faces:\n",
        "#   x,y,w,h = face['box']\n",
        "\n",
        "#   x1 = y\n",
        "#   w1 = y+h\n",
        "#   h1 = x\n",
        "#   y1 = x+w\n",
        "\n",
        "#   a = (x1, y1, w1, h1)\n",
        "#   face_location1.append(a)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wOexZ6Gzrply"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(face_location1)"
      ],
      "metadata": {
        "id": "6UQ3jCHisjVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file_name = \"/content/drive/MyDrive/ML_Project/StudentName.pkl\"\n",
        "\n",
        "\n",
        "# open_file = open(file_name, \"rb\")\n",
        "# personNames = pickle.load(open_file)\n",
        "# open_file.close()\n",
        "\n",
        "\n",
        "# file_name = \"/content/drive/MyDrive/ML_Project/StudentEncoding.pkl\"\n",
        "\n",
        "# open_file = open(file_name, \"rb\")\n",
        "# encodeListKnown = pickle.load(open_file)\n",
        "# open_file.close()"
      ],
      "metadata": {
        "id": "DDIrxKvatQ8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encodesCurrentFrame = face_recognition.face_encodings(image, face_location1)"
      ],
      "metadata": {
        "id": "sr3oIfBPspif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Name_Dist = {}\n",
        "# for encodeFace, faceLoc in zip(encodesCurrentFrame, face_location1):\n",
        "#         matches = face_recognition.compare_faces(encodeListKnown, encodeFace)\n",
        "#         # print(matches)\n",
        "#         faceDis = face_recognition.face_distance(encodeListKnown, encodeFace)\n",
        "#         # print(faceDis)\n",
        "#         matchIndex = np.argmin(faceDis)\n",
        "#         # print(matchIndex)\n",
        "#         if faceDis[matchIndex] < 0.50:\n",
        "#             name = personNames[matchIndex].upper()\n",
        "#             print(name)\n",
        "#             Name_Dist[name] = faceLoc\n",
        "#         else:\n",
        "#             print('Unknown')\n",
        "#             Name_Dist['Unknown'] = faceLoc\n"
      ],
      "metadata": {
        "id": "oboSNJvLsuqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "scYcL_3stF2E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}